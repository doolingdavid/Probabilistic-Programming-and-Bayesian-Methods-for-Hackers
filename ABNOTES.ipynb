{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import Series, DataFrame\n",
    "import pytz\n",
    "from pytz import common_timezones, all_timezones\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "#from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2 Example: Bayesian A/B Testing\n",
    "\n",
    "A/B testing is a statistical design pattern for determining the difference of effectiveness between two different treatments. For example, a pharmaceutical company is interested in the effectiveness of drug A versus drug B. The company will test drug A on some percentage of a patient group, and drug B on the rest (this split is often 50-50, but we will relax this assumption). After performing enough trials, the in-house statisticians measure the effectiveness to determine which drug yielded results.\n",
    "\n",
    "Similarly, front-end Web developers are interested in which design of their Web site yields more _conversions_, where a conversion could be a visitor signing up, purchasing something, or taking some other action. They will route some fraction of visitors to site A, and the other fraction to site B (which has an alternate design), and record if the visit yielded a conversion or not. The assignments and conversions are recorded and analyzed afterward.\n",
    "\n",
    "The key value of A/B tests is that there is only a single difference between groups. Thus, any significant change in the metrics (like drug effectiveness or conversions) can be directly attributed to the difference.\n",
    "\n",
    "Often, the post-experiment analysis is done using something called a \"hypothesis test\" ike a _difference of means test_ or _difference of proportions test_. This involves often misunderstood quantities like a \"Z-score\" and even more confusing \"p-values\" (please don't ask). If you have taken a statistics course, you have probably been taught this technique (although not necessarily _learned_ this technique). And if you were like me, you may have felt uncomfortable with their derivatoin. If so, good. The Bayesian approach to this problem is more natural.\n",
    "\n",
    "\n",
    "\n",
    "## 2.2.3 A Simple Case\n",
    "\n",
    "As this is a _hacker_ book, we'll continue with the web-development example. For the moment, we will focus on the analysis of site A first. Assume that there is some probability, $p_A$, that users who are shown site A eventually convert. This is the true effectiveness of site A. Currently, this quantity is unknown to us.\n",
    "\n",
    "Suppose site A was shown to $N$ people, and $n$ people converted. One might conlcude hastily that $p_A = \\frac{n}{N}$.\n",
    "Unfortunately, the _observed frequency_ $\\frac{n}{N}$ does not necessarily equal $p_A$; there is a difference between the _observed frequency_ and the _true frequency_ of an event. The true frequency can be interpreted as the probability of an event occurring, and this does not necessarily equal the observed frequency. For example, the true frequency of rolling a 1 on a six-sided die is $\\frac{1}{6}$, but if we roll the dice six times we may not see a 1 show up at all (the observed frequency)! We must commonly determine the true frequency of events like:\n",
    "\n",
    "* The fraction of users who make purchases\n",
    "* The proportion of some characteristic in a population\n",
    "* The percentage of Internet users with cats\n",
    "* Or the probability that it will rain tomorrow\n",
    "\n",
    "Unfortunately, noise and complexities hide the true frequency from us and we must _infer_ it from observed data. We use Bayesian statistics to infer probable values of the true frequency using an apprpriate prior and observed data. With respect to our conversion example, we are interested in using what we know, $N$ (the total visitors) and $n$ (the number of conversions), to estimate what $p_A$, the true frequency of conversion, might be.\n",
    "\n",
    "To set up a Bayesian model, we need to assign prior distributions to our unknown quantities. _A priori_, what do you think $p_A$ might be? For this example, we have no strong conviction about $p_A$, so for now, let's assume $p_A$ is uniform over [0,1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
